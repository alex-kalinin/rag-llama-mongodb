{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"275.992px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7468084,"sourceType":"datasetVersion","datasetId":4347140},{"sourceId":4302,"sourceType":"modelInstanceVersion","modelInstanceId":3097}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Prerequisite**\n1. Download LLama Model locally\n  1. https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/tree/main\n2. Preload Sentence Transformer model (run the preload code below)\n\n**Plan**\n\n1. Use PDF document (e.g. a financial report)\n2. Split using SentenceTransformer\n3. Load to MongoDB\n4. Search \n5. Add a prompt\n6. Generate","metadata":{}},{"cell_type":"code","source":"!pip install langchain\n!pip install sentence-transformers\n!pip install \"pymongo[srv]\"\n!pip install typing-inspect==0.8.0 typing_extensions==4.5.0\n!pip install pypdf","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:43:42.308952Z","iopub.execute_input":"2024-01-24T19:43:42.309205Z","iopub.status.idle":"2024-01-24T19:45:03.746654Z","shell.execute_reply.started":"2024-01-24T19:43:42.309181Z","shell.execute_reply":"2024-01-24T19:45:03.745363Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/4c/1a/16ad07ffc514944907582cf7a0f9d61cb1165a7b1bb2650e55c8b37aef19/langchain-0.1.3-py3-none-any.whl.metadata\n  Downloading langchain-0.1.3-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.20)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.5)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.3)\nCollecting jsonpatch<2.0,>=1.33 (from langchain)\n  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain-community<0.1,>=0.0.14 (from langchain)\n  Obtaining dependency information for langchain-community<0.1,>=0.0.14 from https://files.pythonhosted.org/packages/5e/fe/772dd89e3d823bb944bc6428674544dd761ac667eda4c13ec94d1ebc3d05/langchain_community-0.0.15-py3-none-any.whl.metadata\n  Downloading langchain_community-0.0.15-py3-none-any.whl.metadata (7.6 kB)\nCollecting langchain-core<0.2,>=0.1.14 (from langchain)\n  Obtaining dependency information for langchain-core<0.2,>=0.1.14 from https://files.pythonhosted.org/packages/02/fa/076e43665cb54fc21b478d96852174ea42d661586321c321efdaedaaaede/langchain_core-0.1.15-py3-none-any.whl.metadata\n  Downloading langchain_core-0.1.15-py3-none-any.whl.metadata (6.0 kB)\nCollecting langsmith<0.1,>=0.0.83 (from langchain)\n  Obtaining dependency information for langsmith<0.1,>=0.0.83 from https://files.pythonhosted.org/packages/a1/3f/0808382e9d0b504e727dbaf86f1fcbe59472cac17a205644a5f78b11c36b/langsmith-0.0.83-py3-none-any.whl.metadata\n  Downloading langsmith-0.0.83-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.24.3)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.12)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.14->langchain) (3.7.1)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.14->langchain)\n  Obtaining dependency information for packaging<24.0,>=23.2 from https://files.pythonhosted.org/packages/ec/1a/610693ac4ee14fcdf2d9bf3c493370e4f2ef7ae2e19217d7a237ff42367d/packaging-23.2-py3-none-any.whl.metadata\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.14->langchain) (1.1.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nDownloading langchain-0.1.3-py3-none-any.whl (803 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langchain_community-0.0.15-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.15-py3-none-any.whl (229 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, jsonpatch, langsmith, langchain-core, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: jsonpatch\n    Found existing installation: jsonpatch 1.32\n    Uninstalling jsonpatch-1.32:\n      Successfully uninstalled jsonpatch-1.32\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed jsonpatch-1.33 langchain-0.1.3 langchain-community-0.0.15 langchain-core-0.1.15 langsmith-0.0.83 packaging-23.2\nCollecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m977.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.24.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.20.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=f18aa2d64150246e1b06ddcdbd4fa89c864be617b9f2bf5921d65ecd00fae744\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nRequirement already satisfied: pymongo[srv] in /opt/conda/lib/python3.10/site-packages (3.13.0)\nCollecting dnspython<3.0.0,>=1.16.0 (from pymongo[srv])\n  Obtaining dependency information for dnspython<3.0.0,>=1.16.0 from https://files.pythonhosted.org/packages/b6/83/4a684a63d395007670bc95c1947c07045fe66141574e2f7e9e347df8499a/dnspython-2.5.0-py3-none-any.whl.metadata\n  Downloading dnspython-2.5.0-py3-none-any.whl.metadata (5.8 kB)\nDownloading dnspython-2.5.0-py3-none-any.whl (305 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.4/305.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: dnspython\nSuccessfully installed dnspython-2.5.0\nCollecting typing-inspect==0.8.0\n  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\nRequirement already satisfied: typing_extensions==4.5.0 in /opt/conda/lib/python3.10/site-packages (4.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect==0.8.0) (1.0.0)\nInstalling collected packages: typing-inspect\n  Attempting uninstall: typing-inspect\n    Found existing installation: typing-inspect 0.9.0\n    Uninstalling typing-inspect-0.9.0:\n      Successfully uninstalled typing-inspect-0.9.0\nSuccessfully installed typing-inspect-0.8.0\nRequirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (3.17.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.25 --force-reinstall --upgrade --no-cache-dir","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:45:03.748673Z","iopub.execute_input":"2024-01-24T19:45:03.748968Z","iopub.status.idle":"2024-01-24T19:46:36.094906Z","shell.execute_reply.started":"2024-01-24T19:45:03.748942Z","shell.execute_reply":"2024-01-24T19:46:36.093868Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting llama-cpp-python==0.2.25\n  Downloading llama_cpp_python-0.2.25.tar.gz (8.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-cpp-python==0.2.25)\n  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting numpy>=1.20.0 (from llama-cpp-python==0.2.25)\n  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/a5/37/d1453c9ff4f7630e68ec036c6fb56ba0d7c769daa8a4083cb4ef8ee45995/numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python==0.2.25)\n  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m201.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\nBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.25-cp310-cp310-manylinux_2_35_x86_64.whl size=8210102 sha256=1545ec98ed44a4740f84e5f5ca64f2d4b90e13bbb4fa851956ddb70ff68dc489\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ejo55ye6/wheels/6f/7e/23/5a9b41241b41025d10c13e31d005d6c1a6bce58fa02870ee3a\nSuccessfully built llama-cpp-python\nInstalling collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Uninstalling typing_extensions-4.5.0:\n      Successfully uninstalled typing_extensions-4.5.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.3\n    Uninstalling numpy-1.24.3:\n      Successfully uninstalled numpy-1.24.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.3 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.3 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.26.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.26.3 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\nwoodwork 0.27.0 requires numpy<1.25.0,>=1.22.0, but you have numpy 1.26.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.2.25 numpy-1.26.3 typing-extensions-4.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install -U numpy==1.24.1","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:46:36.096637Z","iopub.execute_input":"2024-01-24T19:46:36.097031Z","iopub.status.idle":"2024-01-24T19:46:51.863826Z","shell.execute_reply.started":"2024-01-24T19:46:36.096992Z","shell.execute_reply":"2024-01-24T19:46:51.862598Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting numpy==1.24.1\n  Downloading numpy-1.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.3\n    Uninstalling numpy-1.26.3:\n      Successfully uninstalled numpy-1.26.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.1 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.7.1 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.7.1 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.24.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Pre-load Models","metadata":{}},{"cell_type":"code","source":"def preload():\n    s = SentenceTransformersTokenTextSplitter()\n    emb = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:46:51.866771Z","iopub.execute_input":"2024-01-24T19:46:51.867085Z","iopub.status.idle":"2024-01-24T19:46:51.871988Z","shell.execute_reply.started":"2024-01-24T19:46:51.867055Z","shell.execute_reply":"2024-01-24T19:46:51.871123Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"from pymongo import MongoClient\nimport os\nfrom llama_cpp import Llama\nfrom langchain_community.llms import LlamaCpp\nimport torch\n\n# https://www.sbert.net/docs/pretrained_models.html#model-overview\n# Sentence BERT, based on BERT\nfrom sentence_transformers import SentenceTransformer\n\n# https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.ht\n# https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.SentenceTransformersTokenTextSplitter.html\nfrom langchain.text_splitter import (\n    RecursiveCharacterTextSplitter, \n    SentenceTransformersTokenTextSplitter\n)\nfrom pypdf import PdfReader\n\nimport ctypes\nfrom llama_cpp import llama_log_set\ndef my_log_callback(level, message, user_data):\n    pass\n\nlog_callback = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.c_char_p, ctypes.c_void_p)(my_log_callback)\nllama_log_set(log_callback, ctypes.c_void_p())\n\n# We will keep all global variables in an object to not pullute the global namespace.\nclass Object(object):\n    pass","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:46:51.873531Z","iopub.execute_input":"2024-01-24T19:46:51.873876Z","iopub.status.idle":"2024-01-24T19:46:59.293675Z","shell.execute_reply.started":"2024-01-24T19:46:51.873843Z","shell.execute_reply":"2024-01-24T19:46:59.292828Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"t = Object()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:46:59.294898Z","iopub.execute_input":"2024-01-24T19:46:59.295355Z","iopub.status.idle":"2024-01-24T19:46:59.299289Z","shell.execute_reply.started":"2024-01-24T19:46:59.295328Z","shell.execute_reply":"2024-01-24T19:46:59.298339Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '') != ''","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:46:59.300509Z","iopub.execute_input":"2024-01-24T19:46:59.300773Z","iopub.status.idle":"2024-01-24T19:46:59.311785Z","shell.execute_reply.started":"2024-01-24T19:46:59.300749Z","shell.execute_reply":"2024-01-24T19:46:59.310932Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## MongoDB Config","metadata":{}},{"cell_type":"code","source":"if KAGGLE:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    t.uri = user_secrets.get_secret(\"MONGODB_URI\")\nelse:\n    t.uri = os.environ[\"MONGODB_URI\"]\n# Create a new client and connect to the server\nt.client = MongoClient(t.uri)\n# Send a ping to confirm a successful connection\ntry:\n    t.client.admin.command('ping')\n    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\nexcept Exception as e:\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:46:59.312983Z","iopub.execute_input":"2024-01-24T19:46:59.313846Z","iopub.status.idle":"2024-01-24T19:47:00.021320Z","shell.execute_reply.started":"2024-01-24T19:46:59.313813Z","shell.execute_reply":"2024-01-24T19:47:00.020443Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Pinged your deployment. You successfully connected to MongoDB!\n","output_type":"stream"}]},{"cell_type":"code","source":"t.db = t.client.rag_llama\nt.coll = t.db.mdb","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:47:00.022721Z","iopub.execute_input":"2024-01-24T19:47:00.023015Z","iopub.status.idle":"2024-01-24T19:47:00.027496Z","shell.execute_reply.started":"2024-01-24T19:47:00.022990Z","shell.execute_reply":"2024-01-24T19:47:00.026621Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if KAGGLE:\n    !wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q6_K.gguf    \n    preload()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:47:00.030878Z","iopub.execute_input":"2024-01-24T19:47:00.031155Z","iopub.status.idle":"2024-01-24T19:48:19.392846Z","shell.execute_reply.started":"2024-01-24T19:47:00.031131Z","shell.execute_reply":"2024-01-24T19:48:19.391957Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"--2024-01-24 19:47:00--  https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q6_K.gguf\nResolving huggingface.co (huggingface.co)... 65.8.243.16, 65.8.243.46, 65.8.243.92, ...\nConnecting to huggingface.co (huggingface.co)|65.8.243.16|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs.huggingface.co/repos/8d/b1/8db1d1f73b4caa58e947ccbfe2fb27ac5e495c2ad8457ad299d15987aee3b520/5da6e8997c8fbb042d6b981270756e6fc8065e89fde5215b18ee1e93c87dba3f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.Q6_K.gguf%3B+filename%3D%22llama-2-13b-chat.Q6_K.gguf%22%3B&Expires=1706384821&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNjM4NDgyMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84ZC9iMS84ZGIxZDFmNzNiNGNhYTU4ZTk0N2NjYmZlMmZiMjdhYzVlNDk1YzJhZDg0NTdhZDI5OWQxNTk4N2FlZTNiNTIwLzVkYTZlODk5N2M4ZmJiMDQyZDZiOTgxMjcwNzU2ZTZmYzgwNjVlODlmZGU1MjE1YjE4ZWUxZTkzYzg3ZGJhM2Y%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=vSvJMJoeY6ZOPMEk1JLYfkFdBoSZcBHjFL7-58-1nxuwVoh9Q6ncEH0L2WrAMbc458sc8r26U9U2s2b8KhYbpnVNjUdtKL451lr9lj4bAZ3VSsf9qvkONRrhwPNWnT5%7Etk1Nml6WIv409HOM89nQ6LmZLPbLd0BWKHZQr3bFu5QURmyu-YPWEYAgibvAb4BEy7IQP%7ENdOuR1Zn3PHJQg8aFjGmCJp9HXMOUsvIWwxzEoM1T7vYQK54Y9Muf4Aw4cVItd3JBcYNpbc1jHuo3Oz4SGsEPG7tAQtb4GMv0g-8W9FRfdPbsk0C1k-dYudrI7mIriYF6Y2vzZjd5M9exe0A__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n--2024-01-24 19:47:01--  https://cdn-lfs.huggingface.co/repos/8d/b1/8db1d1f73b4caa58e947ccbfe2fb27ac5e495c2ad8457ad299d15987aee3b520/5da6e8997c8fbb042d6b981270756e6fc8065e89fde5215b18ee1e93c87dba3f?response-content-disposition=attachment%3B+filename*%3DUTF-8''llama-2-13b-chat.Q6_K.gguf%3B+filename%3D%22llama-2-13b-chat.Q6_K.gguf%22%3B&Expires=1706384821&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNjM4NDgyMX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84ZC9iMS84ZGIxZDFmNzNiNGNhYTU4ZTk0N2NjYmZlMmZiMjdhYzVlNDk1YzJhZDg0NTdhZDI5OWQxNTk4N2FlZTNiNTIwLzVkYTZlODk5N2M4ZmJiMDQyZDZiOTgxMjcwNzU2ZTZmYzgwNjVlODlmZGU1MjE1YjE4ZWUxZTkzYzg3ZGJhM2Y~cmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=vSvJMJoeY6ZOPMEk1JLYfkFdBoSZcBHjFL7-58-1nxuwVoh9Q6ncEH0L2WrAMbc458sc8r26U9U2s2b8KhYbpnVNjUdtKL451lr9lj4bAZ3VSsf9qvkONRrhwPNWnT5~tk1Nml6WIv409HOM89nQ6LmZLPbLd0BWKHZQr3bFu5QURmyu-YPWEYAgibvAb4BEy7IQP~NdOuR1Zn3PHJQg8aFjGmCJp9HXMOUsvIWwxzEoM1T7vYQK54Y9Muf4Aw4cVItd3JBcYNpbc1jHuo3Oz4SGsEPG7tAQtb4GMv0g-8W9FRfdPbsk0C1k-dYudrI7mIriYF6Y2vzZjd5M9exe0A__&Key-Pair-Id=KVTP0A1DKRTAX\nResolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.101.47, 18.154.101.104, 18.154.101.87, ...\nConnecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.101.47|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10679140224 (9.9G) [binary/octet-stream]\nSaving to: 'llama-2-13b-chat.Q6_K.gguf'\n\nllama-2-13b-chat.Q6 100%[===================>]   9.95G   180MB/s    in 66s     \n\n2024-01-24 19:48:07 (154 MB/s) - 'llama-2-13b-chat.Q6_K.gguf' saved [10679140224/10679140224]\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e344f3d0abd04772a9ddf768f7bb4c64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1431b2ce9c842779c68a1c49147eecc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ad1f4981be9410b8cc78cb82706eba3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10c570696e0c4794a08f45e9b70b76a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96c4248c9f3348e2aa4dda13cb9311c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc1a1965be1491dbb08c8d2430a45c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"987960f70bed43e5b76e9b850c7a74e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5a959c61954fac82cbadf4df832522"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"142659d636554165beb230cca989f67c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4515c09527a4456a0bfa35a232ab705"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df6681b841a447998f2b5618454efefb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07654f400bd8406aa1f6e9a99bd8b1af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7f05fa37a224a458c97ed341f6b686a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d131b41fb3d84d16a43eec06b29b8423"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/737 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fcc01a67a2b467f8b7dbb09e86d6edb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"333da543f207433cb4dffa82a590dd81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/9.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ede3eecb64524e3baa654df0ee866d12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e767e64f60474071b29140eeaccb496b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5567b6b0ec2444d483ee8e8476245a4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"804e272e3f884f6fba66e5cfb606e48a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd115540c4446759c42ff634c56cccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153f57e26267454fa0b05cf1005faf2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e218699d9e2048b8ad9d843d0bacb637"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342f9230216241859ef3323a0d6c9ec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69e67c33d3b84865ade3441bf8d5698f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3e9626ee5c14be4b3862fe26ec38e58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecdc6df438a94315a043802e8b97002b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515d6385202c4392b2fc4dbe67413157"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Llama Config","metadata":{}},{"cell_type":"code","source":"# t.model_path = \"../../data\"\nif KAGGLE:\n    t.llm_path = \"/kaggle/working/llama-2-13b-chat.Q6_K.gguf\"\n    t.layers = 50\nelse:    \n    t.model_path = \"../../../../data\"\n    t.llm_path = f\"{t.model_path}/llama/llama-2-13b-chat.Q6_K.gguf\"\n    t.layers = 50","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:49:13.671596Z","iopub.execute_input":"2024-01-24T19:49:13.671977Z","iopub.status.idle":"2024-01-24T19:49:13.677290Z","shell.execute_reply.started":"2024-01-24T19:49:13.671931Z","shell.execute_reply":"2024-01-24T19:49:13.676286Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Load and Parse Documents","metadata":{}},{"cell_type":"code","source":"# t.reader = PdfReader(\"data/brk-2023-q3.pdf\")\n# t.reader = PdfReader(\"data/msft-2022.pdf\")\nif KAGGLE:\n    t.reader = PdfReader(f\"../input/mdb-pdf/{t.coll.name}-2022.pdf\")\nelse:\n    t.reader = PdfReader(f\"data/{t.coll.name}-2022.pdf\")\nt.pages = [p.extract_text().strip() for p in t.reader.pages]","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:49:13.679012Z","iopub.execute_input":"2024-01-24T19:49:13.679294Z","iopub.status.idle":"2024-01-24T19:49:48.555595Z","shell.execute_reply.started":"2024-01-24T19:49:13.679269Z","shell.execute_reply":"2024-01-24T19:49:48.554779Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Pages are of various sizes. We need to split into chunks that fit into the model window, specifically, the BERT embedding 256-token sized window. \n\nSo we'll join all pages, and use the SentenceTransformer splitter to split the doc into the chunks of the right size.","metadata":{}},{"cell_type":"code","source":"# print(t.pages[10])","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:49:48.556633Z","iopub.execute_input":"2024-01-24T19:49:48.556910Z","iopub.status.idle":"2024-01-24T19:49:48.561149Z","shell.execute_reply.started":"2024-01-24T19:49:48.556885Z","shell.execute_reply":"2024-01-24T19:49:48.560172Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"t.ch_splitter =  RecursiveCharacterTextSplitter(\n    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n    chunk_size=1024,\n    chunk_overlap=0\n)\nt.ch_chunks = t.ch_splitter.split_text(\"\\n\".join(t.pages))\nlen(t.ch_chunks)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:49:48.562511Z","iopub.execute_input":"2024-01-24T19:49:48.562903Z","iopub.status.idle":"2024-01-24T19:49:48.593178Z","shell.execute_reply.started":"2024-01-24T19:49:48.562866Z","shell.execute_reply":"2024-01-24T19:49:48.592352Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"573"},"metadata":{}}]},{"cell_type":"code","source":"t.token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=10, tokens_per_chunk=256)\nt.token_chunks = []\nfor ch in t.ch_chunks:\n    t.token_chunks.extend(t.token_splitter.split_text(ch))\nlen(t.token_chunks)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:49:48.595869Z","iopub.execute_input":"2024-01-24T19:49:48.596138Z","iopub.status.idle":"2024-01-24T19:50:01.793247Z","shell.execute_reply.started":"2024-01-24T19:49:48.596113Z","shell.execute_reply":"2024-01-24T19:50:01.792408Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"594"},"metadata":{}}]},{"cell_type":"markdown","source":"## Embedding Model","metadata":{}},{"cell_type":"code","source":"t.emb_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:01.794324Z","iopub.execute_input":"2024-01-24T19:50:01.794948Z","iopub.status.idle":"2024-01-24T19:50:02.227250Z","shell.execute_reply.started":"2024-01-24T19:50:01.794916Z","shell.execute_reply":"2024-01-24T19:50:02.226498Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"len(t.emb_model.encode(t.token_chunks[21]).tolist())","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:02.228596Z","iopub.execute_input":"2024-01-24T19:50:02.228990Z","iopub.status.idle":"2024-01-24T19:50:03.415302Z","shell.execute_reply.started":"2024-01-24T19:50:02.228952Z","shell.execute_reply":"2024-01-24T19:50:03.414236Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a326b52ad8341afa2211df9fdd241c8"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}]},{"cell_type":"markdown","source":"## Upload documents","metadata":{}},{"cell_type":"code","source":"len(list(t.coll.find().limit(10)))","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:03.417030Z","iopub.execute_input":"2024-01-24T19:50:03.417659Z","iopub.status.idle":"2024-01-24T19:50:03.594357Z","shell.execute_reply.started":"2024-01-24T19:50:03.417621Z","shell.execute_reply":"2024-01-24T19:50:03.593358Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"# _ = t.coll.insert_many(t.docs)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:25.348728Z","iopub.execute_input":"2024-01-24T19:50:25.349110Z","iopub.status.idle":"2024-01-24T19:50:25.355555Z","shell.execute_reply.started":"2024-01-24T19:50:25.349075Z","shell.execute_reply":"2024-01-24T19:50:25.352428Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"len(list(t.coll.find().limit(10)))","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:25.356860Z","iopub.execute_input":"2024-01-24T19:50:25.357209Z","iopub.status.idle":"2024-01-24T19:50:25.574680Z","shell.execute_reply.started":"2024-01-24T19:50:25.357165Z","shell.execute_reply":"2024-01-24T19:50:25.573777Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"markdown","source":"## Query Index","metadata":{}},{"cell_type":"markdown","source":"Index definition:\n\n```\n{\n  \"fields\": [\n    {\n      \"type\": \"vector\",\n      \"path\": \"emb\",\n      \"numDimensions\": 768,\n      \"similarity\": \"dotProduct\"\n    }\n  ]\n}\n```","metadata":{}},{"cell_type":"code","source":"t.query = \"What was the total revenue?\"\n\nt.results = t.coll.aggregate([{\n    \"$vectorSearch\": {\n        \"queryVector\": t.emb_model.encode(t.query).tolist(),\n        \"path\": \"embedding\",\n        \"numCandidates\": 100,\n        \"limit\": 8,\n        \"index\": f\"{t.coll.name}_vector_index\"\n    }}])\n\nt.context = \"\\n\\n\".join([d['text'] for d in t.results])","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:25.575836Z","iopub.execute_input":"2024-01-24T19:50:25.576176Z","iopub.status.idle":"2024-01-24T19:50:25.777400Z","shell.execute_reply.started":"2024-01-24T19:50:25.576143Z","shell.execute_reply":"2024-01-24T19:50:25.776707Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4be2e4da3dc4fb3a71880d1ea22de27"}},"metadata":{}}]},{"cell_type":"code","source":"print(t.context[0:1000])","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:25.778418Z","iopub.execute_input":"2024-01-24T19:50:25.778719Z","iopub.status.idle":"2024-01-24T19:50:25.783509Z","shell.execute_reply.started":"2024-01-24T19:50:25.778693Z","shell.execute_reply":"2024-01-24T19:50:25.782578Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"operations ( in thousands of u. s. dollars, except share and per share data ) years ended january 31, 2023 2022 2021 revenue : subscription $ 1, 235, 122 $ 842, 047 $ 565, 349 services 48, 918 31, 735 25, 031\n\nthe following table presents the company ’ s revenues disaggregated by primary geographical markets, subscription product categories and services ( in thousands ) : years ended january 31, 2023 2022 2021 primary geographical markets : americas $ 781, 763 $ 527, 081 $ 361, 351 emea 361, 566 257, 846 177, 448 asia pacific 140, 711 88, 855 51, 581 total $ 1, 284, 040 $ 873, 782 $ 590, 380 subscription product categories and services : mongodb atlas - related $ 808, 263 $ 492, 287 $ 270, 805 other subscription 426, 859 349, 760 294, 544 services 48, 918 31, 735 25, 031 total $ 1, 284, 040 $ 873, 782 $ 590, 380 customers located in the united states accounted for 55 %, 54 % and 56 % of total revenue for the years ended january 31, 2023, 2022 and 2021, respectively. customers located i\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load LLama","metadata":{}},{"cell_type":"code","source":"from langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n\n# https://python.langchain.com/docs/guides/local_llms\nt.llm = LlamaCpp(\n    model_path=t.llm_path,\n    n_gpu_layers=t.layers,\n    n_threads=10, \n    n_ctx=4096, \n    n_batch=512,\n    verbose=False,\n    f16_kv=True,\n    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:25.789117Z","iopub.execute_input":"2024-01-24T19:50:25.789394Z","iopub.status.idle":"2024-01-24T19:50:32.458953Z","shell.execute_reply.started":"2024-01-24T19:50:25.789353Z","shell.execute_reply":"2024-01-24T19:50:32.458055Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\nggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\nggml_init_cublas: found 2 CUDA devices:\n  Device 0: Tesla T4, compute capability 7.5\n  Device 1: Tesla T4, compute capability 7.5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Query LLaMa","metadata":{}},{"cell_type":"code","source":"def ask(prompt, temp=0.8, top_p=0.95):\n    out = t.llm.invoke(\n        prompt, \n        max_tokens=512, \n        stop=[\"Q:\"], \n        temperature=temp,\n        top_p=top_p,\n        top_k=10,\n        repeat_penalty=1.2,\n    )\n    return out","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:32.460156Z","iopub.execute_input":"2024-01-24T19:50:32.460492Z","iopub.status.idle":"2024-01-24T19:50:32.465748Z","shell.execute_reply.started":"2024-01-24T19:50:32.460464Z","shell.execute_reply":"2024-01-24T19:50:32.464756Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"Prompt Format:\n```\n<s>[INST] <<SYS>>\n{{ system_prompt }}\n<</SYS>>\n\n{{ user_message }} [/INST]\n```","metadata":{}},{"cell_type":"markdown","source":"### Query with RAG","metadata":{}},{"cell_type":"code","source":"def ask_with_context(question, context):\n    full_prompt = (\n    \"<s>[INST]<<SYS>>\\n\"\n    + \"You are a helpful expert financial research assistant.\" \n    + \"You answer questions about about information contained in a financial report.\"\n    + \"You will be given the user's question, and the relevant informaton from \" \n    + \"the financial report. Answer the question using only this information\" \n    + \"\\n<</SYS>>\\n\\n\"\n    + \"Information: {context}\\n\"\n    + \"Question: {question}\\n\"\n    + \"Answer:\\n\"\n    + \"[/INST]\"\n    )\n    full_prompt = full_prompt.replace(\"{context}\", context)\n    full_prompt = full_prompt.replace(\"{question}\", question)\n    ask(full_prompt)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:32.466935Z","iopub.execute_input":"2024-01-24T19:50:32.467208Z","iopub.status.idle":"2024-01-24T19:50:32.476664Z","shell.execute_reply.started":"2024-01-24T19:50:32.467183Z","shell.execute_reply":"2024-01-24T19:50:32.475822Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def find_context(question):\n    results = t.coll.aggregate([{\n    \"$vectorSearch\": {\n        \"queryVector\": t.emb_model.encode(question).tolist(),\n        \"path\": \"embedding\",\n        \"numCandidates\": 200,\n        \"limit\": 8,\n        \"index\": f\"{t.coll.name}_vector_index\"\n    }}])\n    result_texts = [d['text'] for d in results]\n    assert len(result_texts) > 0\n    context = \"\\n\\n\".join(result_texts)\n    return context","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:32.477656Z","iopub.execute_input":"2024-01-24T19:50:32.477903Z","iopub.status.idle":"2024-01-24T19:50:32.488768Z","shell.execute_reply.started":"2024-01-24T19:50:32.477881Z","shell.execute_reply":"2024-01-24T19:50:32.487924Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def ask_with_rag(question):\n    context = find_context(question)\n    ask_with_context(question, context)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:32.489698Z","iopub.execute_input":"2024-01-24T19:50:32.489957Z","iopub.status.idle":"2024-01-24T19:50:32.499197Z","shell.execute_reply.started":"2024-01-24T19:50:32.489934Z","shell.execute_reply":"2024-01-24T19:50:32.498367Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"%%time\nask_with_rag(\"What was the total revenue?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:50:32.500412Z","iopub.execute_input":"2024-01-24T19:50:32.501258Z","iopub.status.idle":"2024-01-24T19:51:58.547421Z","shell.execute_reply.started":"2024-01-24T19:50:32.501224Z","shell.execute_reply":"2024-01-24T19:51:58.546427Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"550d10b150ab4b22b1e5df3c9bae1107"}},"metadata":{}},{"name":"stdout","text":"  Sure! Based on the information provided in the financial report, the total revenue for the year ended January 31, 2023 was $1,284.0 million.","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nask_with_rag(\"What was the operating income or loss?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:51:58.548731Z","iopub.execute_input":"2024-01-24T19:51:58.549041Z","iopub.status.idle":"2024-01-24T19:53:45.396493Z","shell.execute_reply.started":"2024-01-24T19:51:58.549015Z","shell.execute_reply":"2024-01-24T19:53:45.395498Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57c10bf5328c40bea59f7174de4a6dc7"}},"metadata":{}},{"name":"stdout","text":"  Based on the information provided in the financial report, the operating loss for the years ended January 31, 2023, 2022 and 2021 was as follows:\n\nYear Ended January 31, 2023:\nOperating loss = $ (346,655)\n\nYear Ended January 31, 2022:\nOperating loss = $ (289,364)\n\nYear Ended January 31, 2021:\nOperating loss = $ (209,304)","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nask_with_rag(\"What was the operating income or loss in year 2022?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:53:45.398149Z","iopub.execute_input":"2024-01-24T19:53:45.398591Z","iopub.status.idle":"2024-01-24T19:55:00.667835Z","shell.execute_reply.started":"2024-01-24T19:53:45.398552Z","shell.execute_reply":"2024-01-24T19:55:00.666807Z"},"trusted":true},"execution_count":37,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34237c919d78482588ad3dc3f66b4c8a"}},"metadata":{}},{"name":"stdout","text":"  Based on the information provided in the financial report, the operating income (loss) for the year ended January 31, 2022 was:\n\nOperating loss: $(302,889)","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nask_with_rag(\"Compare the total revenue between the years 2023 and 2022\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:55:00.669028Z","iopub.execute_input":"2024-01-24T19:55:00.669323Z","iopub.status.idle":"2024-01-24T19:56:36.920756Z","shell.execute_reply.started":"2024-01-24T19:55:00.669297Z","shell.execute_reply":"2024-01-24T19:56:36.919195Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf29ff847498429590f9421f6a5ea671"}},"metadata":{}},{"name":"stdout","text":"  Sure! Based on the information provided, the total revenue for the year ended January 31, 2023 was $1,284.0 million, while the total revenue for the year ended January 31, 2022 was $873.8 million. This represents an increase of $410.2 million or 47% from 2022 to 2023.CPU times: user 1min 36s, sys: 112 ms, total: 1min 36s\nWall time: 1min 36s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nask_with_rag(\"What time period does the report cover?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:56:36.922024Z","iopub.execute_input":"2024-01-24T19:56:36.922345Z","iopub.status.idle":"2024-01-24T19:57:24.290307Z","shell.execute_reply.started":"2024-01-24T19:56:36.922316Z","shell.execute_reply":"2024-01-24T19:57:24.289363Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"054cd335bf2c43d8bb981931aee42a83"}},"metadata":{}},{"name":"stdout","text":"  Based on the information provided in the report, the period covered is the fiscal year ended January 31, 2023.CPU times: user 47.3 s, sys: 68.9 ms, total: 47.3 s\nWall time: 47.4 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nask_with_rag(\"Were there any changes to the executive team?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:57:24.291519Z","iopub.execute_input":"2024-01-24T19:57:24.291813Z","iopub.status.idle":"2024-01-24T19:59:04.713435Z","shell.execute_reply.started":"2024-01-24T19:57:24.291788Z","shell.execute_reply":"2024-01-24T19:59:04.712531Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616cb45bc8334b71ad1d024ac72823ef"}},"metadata":{}},{"name":"stdout","text":"  Based on the information provided in the financial report, there were no changes to the executive team during the period covered by the report (January 31, 2023). The signature page of the report lists the current members of the executive team, including Dev Ittycheria as President and Chief Executive Officer, Michael Gordon as Chief Operating Officer and Chief Financial Officer, Thomas Bull as Chief Accounting Officer, Tom Killalea as Director, Archana Agrawal as Director, Roelof Botha as Director, Hope Cochran as Director, Francisco D'Souza as Director, and Charles M. Hazard Jr. as Director.CPU times: user 1min 40s, sys: 132 ms, total: 1min 40s\nWall time: 1min 40s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Query Embedded Knowledge","metadata":{}},{"cell_type":"code","source":"def ask_llm(question):\n    prompt = (\n        f\"<s>[INST]<<SYS>>\\n\"\n        + f\"You are a helpful expert financial research assistant.\" \n        + f\"\\n<</SYS>>\\n\\n\"\n        + f\"Question: {question}\\n\"\n        + f\"Answer:\\n\"\n        + f\"[/INST]\"\n    )\n    ask(prompt)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:59:04.714964Z","iopub.execute_input":"2024-01-24T19:59:04.715343Z","iopub.status.idle":"2024-01-24T19:59:04.720705Z","shell.execute_reply.started":"2024-01-24T19:59:04.715303Z","shell.execute_reply":"2024-01-24T19:59:04.719791Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"%%time\nask_llm(\"What was the total revenue of MongoDB in the year ended January 31, 2023?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:59:04.721835Z","iopub.execute_input":"2024-01-24T19:59:04.722097Z","iopub.status.idle":"2024-01-24T19:59:13.387494Z","shell.execute_reply.started":"2024-01-24T19:59:04.722073Z","shell.execute_reply":"2024-01-24T19:59:13.386560Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"  As a helpful expert financial research assistant, I can provide you with the information you need. According to MongoDB's latest annual report filed on Form 10-K for the fiscal year ended January 31, 2023, the company's total revenue was $1,457 million.","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nask_llm(\"Were there any changes to the executive team at MongoDB in the year ended January 31, 2023?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T19:59:13.388833Z","iopub.execute_input":"2024-01-24T19:59:13.389218Z","iopub.status.idle":"2024-01-24T20:00:01.265674Z","shell.execute_reply.started":"2024-01-24T19:59:13.389183Z","shell.execute_reply":"2024-01-24T20:00:01.264643Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"  As a helpful expert financial research assistant, I can provide you with information on changes to the executive team at MongoDB for the year ended January 31, 2023.\n\nAccording to MongoDB's annual report filed with the Securities and Exchange Commission (SEC) on February 28, 2023, there were no changes to the executive team during the fiscal year ending January 31, 2023. The Executive Team remained unchanged throughout the period.\n\nThe following individuals continue to serve as members of MongoDB's Executive Team:\n\n1. Dev Ittycheria - President and Chief Executive Officer (CEO)\n2. Eliot Horowitz - Co-Founder, Chairman of the Board, and Chief Technology Officer (CTO)\n3. Dwight Merriman - Co-Founder and Head of Product\n4. Kevin P. Mahaffey - Chief Information Security Officer (CISO)\n5. Raj R. Rao - Chief Financial Officer (CFO)\n6. Sarah A. Watts - General Counsel and Secretary\n7. Matt C. Stinchcomb - Senior Vice President, Worldwide Field Operations\n8. Michael J. Gordon - Senior Vice President, Engineering\n9. Andrew S. Wigglesworth - Senior Vice President, Product Management\n10. Ashish G. Shah - Senior Vice President, Corporate Development and Strategy.\n\nPlease note that this information is accurate as of the filing date of MongoDB's annual report and may be subject to change after that date.","output_type":"stream"}]},{"cell_type":"markdown","source":"## LangChain","metadata":{}},{"cell_type":"markdown","source":"We'll use LangChain to tie this all together into a simple API.","metadata":{}},{"cell_type":"code","source":"# https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas\n\nfrom langchain.chains import RetrievalQA\nfrom langchain_community.vectorstores import MongoDBAtlasVectorSearch\nfrom langchain_community.embeddings import HuggingFaceEmbeddings","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:01.266861Z","iopub.execute_input":"2024-01-24T20:00:01.267148Z","iopub.status.idle":"2024-01-24T20:00:03.568766Z","shell.execute_reply.started":"2024-01-24T20:00:01.267123Z","shell.execute_reply":"2024-01-24T20:00:03.567948Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"l = Object()\nl.llm = t.llm","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:03.569924Z","iopub.execute_input":"2024-01-24T20:00:03.570707Z","iopub.status.idle":"2024-01-24T20:00:03.574778Z","shell.execute_reply.started":"2024-01-24T20:00:03.570669Z","shell.execute_reply":"2024-01-24T20:00:03.573910Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"l.lang_emb = HuggingFaceEmbeddings(model_name=\"multi-qa-mpnet-base-cos-v1\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:03.575860Z","iopub.execute_input":"2024-01-24T20:00:03.576144Z","iopub.status.idle":"2024-01-24T20:00:04.079574Z","shell.execute_reply.started":"2024-01-24T20:00:03.576119Z","shell.execute_reply":"2024-01-24T20:00:04.078438Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Check that the embeddings model returns embeddings of the correct size of 768:","metadata":{}},{"cell_type":"code","source":"len(l.lang_emb.embed_documents(['This is a test document'])[0])","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.080960Z","iopub.execute_input":"2024-01-24T20:00:04.081361Z","iopub.status.idle":"2024-01-24T20:00:04.239367Z","shell.execute_reply.started":"2024-01-24T20:00:04.081321Z","shell.execute_reply":"2024-01-24T20:00:04.238405Z"},"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9a15abb619429c9971be4faacaf76a"}},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"768"},"metadata":{}}]},{"cell_type":"code","source":"l.vector_search = MongoDBAtlasVectorSearch(\n    t.coll, \n    l.lang_emb, \n    index_name=\"mdb_vector_index\",\n    embedding_key=\"embedding\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.240985Z","iopub.execute_input":"2024-01-24T20:00:04.241406Z","iopub.status.idle":"2024-01-24T20:00:04.246135Z","shell.execute_reply.started":"2024-01-24T20:00:04.241356Z","shell.execute_reply":"2024-01-24T20:00:04.245263Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"l.results = list(l.vector_search.max_marginal_relevance_search(\n    query=\"What was the total revenue?\",\n    k = 8,\n))","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.247275Z","iopub.execute_input":"2024-01-24T20:00:04.247634Z","iopub.status.idle":"2024-01-24T20:00:04.527297Z","shell.execute_reply.started":"2024-01-24T20:00:04.247601Z","shell.execute_reply":"2024-01-24T20:00:04.526081Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3901ba669bb34cf29d35d67ad267ff06"}},"metadata":{}}]},{"cell_type":"code","source":"len(l.results)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.533143Z","iopub.execute_input":"2024-01-24T20:00:04.536442Z","iopub.status.idle":"2024-01-24T20:00:04.549402Z","shell.execute_reply.started":"2024-01-24T20:00:04.536391Z","shell.execute_reply":"2024-01-24T20:00:04.547888Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"8"},"metadata":{}}]},{"cell_type":"markdown","source":"### Make a Retriever Object","metadata":{}},{"cell_type":"code","source":"l.retriever = l.vector_search.as_retriever(search_kwargs={\"k\": 8})","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.555396Z","iopub.execute_input":"2024-01-24T20:00:04.558590Z","iopub.status.idle":"2024-01-24T20:00:04.566953Z","shell.execute_reply.started":"2024-01-24T20:00:04.558541Z","shell.execute_reply":"2024-01-24T20:00:04.565665Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Make the end-to-end chain object","metadata":{}},{"cell_type":"code","source":"l.qa = RetrievalQA.from_chain_type(\n    llm=l.llm, \n    retriever=l.retriever)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.573188Z","iopub.execute_input":"2024-01-24T20:00:04.576916Z","iopub.status.idle":"2024-01-24T20:00:04.586586Z","shell.execute_reply.started":"2024-01-24T20:00:04.576868Z","shell.execute_reply":"2024-01-24T20:00:04.585322Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"### Query LLM with LangChain","metadata":{}},{"cell_type":"code","source":"%%time\nl.qa.invoke(\"What was the total revenue?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:00:04.590575Z","iopub.execute_input":"2024-01-24T20:00:04.592235Z","iopub.status.idle":"2024-01-24T20:01:26.445363Z","shell.execute_reply.started":"2024-01-24T20:00:04.592191Z","shell.execute_reply":"2024-01-24T20:01:26.444260Z"},"trusted":true},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ed7ce47019f40408ab15f40be5d8150"}},"metadata":{}},{"name":"stdout","text":" Based on the information provided, the total revenue for the year ended January 31, 2023, was $1,284.0 million.","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'query': 'What was the total revenue?',\n 'result': ' Based on the information provided, the total revenue for the year ended January 31, 2023, was $1,284.0 million.'}"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nl.qa.invoke(\"What time period does the report cover?\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T20:01:26.446791Z","iopub.execute_input":"2024-01-24T20:01:26.447174Z","iopub.status.idle":"2024-01-24T20:02:11.596024Z","shell.execute_reply.started":"2024-01-24T20:01:26.447138Z","shell.execute_reply":"2024-01-24T20:02:11.595013Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d2a237506f4e5abfed3686361a0ee3"}},"metadata":{}},{"name":"stdout","text":" Based on the given information, the report covers the fiscal year ended January 31, 2023.","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"{'query': 'What time period does the report cover?',\n 'result': ' Based on the given information, the report covers the fiscal year ended January 31, 2023.'}"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}