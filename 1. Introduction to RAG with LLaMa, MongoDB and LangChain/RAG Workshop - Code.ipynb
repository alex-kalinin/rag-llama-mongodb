{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ece54b7",
   "metadata": {},
   "source": [
    "**Prerequisite**\n",
    "1. Download LLama Model locally\n",
    "  1. https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/tree/main\n",
    "2. Preload Sentence Transformer model (run the preload code below)\n",
    "\n",
    "**Plan**\n",
    "\n",
    "1. Use PDF document (e.g. a financial report)\n",
    "2. Split using SentenceTransformer\n",
    "3. Load to MongoDB\n",
    "4. Search \n",
    "5. Add a prompt\n",
    "6. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install typing-inspect==0.8.0 typing_extensions==4.5.0\n",
    "# !pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cc428",
   "metadata": {},
   "source": [
    "### Pre-load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ce1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload():\n",
    "    s = SentenceTransformersTokenTextSplitter()\n",
    "    emb = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')\n",
    "    \n",
    "# preload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e553689",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b86fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "from llama_cpp import Llama\n",
    "from langchain_community.llms import LlamaCpp\n",
    "import torch\n",
    "\n",
    "# https://www.sbert.net/docs/pretrained_models.html#model-overview\n",
    "# Sentence BERT, based on BERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.ht\n",
    "# https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.SentenceTransformersTokenTextSplitter.html\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    SentenceTransformersTokenTextSplitter\n",
    ")\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import ctypes\n",
    "from llama_cpp import llama_log_set\n",
    "def my_log_callback(level, message, user_data):\n",
    "    pass\n",
    "\n",
    "log_callback = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.c_char_p, ctypes.c_void_p)(my_log_callback)\n",
    "llama_log_set(log_callback, ctypes.c_void_p())\n",
    "\n",
    "# We will keep all global variables in an object to not pullute the global namespace.\n",
    "class Object(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773d0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Object()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264a732",
   "metadata": {},
   "source": [
    "## MongoDB Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7706aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.uri = os.environ[\"MONGODB_URI\"]\n",
    "# Create a new client and connect to the server\n",
    "t.client = MongoClient(t.uri)\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    t.client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc8fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.db = t.client.rag_llama\n",
    "t.coll = t.db.mdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a612863",
   "metadata": {},
   "source": [
    "## Llama Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f76ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.model_path = \"../../data\"\n",
    "t.model_path = \"../../../../data\"\n",
    "t.llm_path = f\"{t.model_path}/llama/llama-2-13b-chat.Q6_K.gguf\"\n",
    "t.layers = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322e60c",
   "metadata": {},
   "source": [
    "## Load and Parse Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t.reader = PdfReader(\"data/brk-2023-q3.pdf\")\n",
    "# t.reader = PdfReader(\"data/msft-2022.pdf\")\n",
    "t.reader = PdfReader(f\"data/{t.coll.name}-2022.pdf\")\n",
    "t.pages = [p.extract_text().strip() for p in t.reader.pages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ce361",
   "metadata": {},
   "source": [
    "Pages are of various sizes. We need to split into chunks that fit into the model window, specifically, the BERT embedding 256-token sized window. \n",
    "\n",
    "So we'll join all pages, and use the SentenceTransformer splitter to split the doc into the chunks of the right size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(t.pages[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.ch_splitter =  RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "t.ch_chunks = t.ch_splitter.split_text(\"\\n\".join(t.pages))\n",
    "len(t.ch_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=10, tokens_per_chunk=256)\n",
    "t.token_chunks = []\n",
    "for ch in t.ch_chunks:\n",
    "    t.token_chunks.extend(t.token_splitter.split_text(ch))\n",
    "len(t.token_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2956c",
   "metadata": {},
   "source": [
    "## Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2601c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.emb_model = SentenceTransformer('sentence-transformers/multi-qa-mpnet-base-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(t.emb_model.encode(t.token_chunks[21]).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bba1d6",
   "metadata": {},
   "source": [
    "## Upload documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(t.coll.find().limit(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.docs = []\n",
    "for t.ch in t.token_chunks:\n",
    "    t.doc = {\n",
    "        \"text\": t.ch,\n",
    "        \"embedding\": t.emb_model.encode(t.ch).tolist()\n",
    "    }\n",
    "    t.docs.append(t.doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43515a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = t.coll.insert_many(t.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7938497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(t.coll.find().limit(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc351e0b",
   "metadata": {},
   "source": [
    "## Query Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a22ec84",
   "metadata": {},
   "source": [
    "Index definition:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"emb\",\n",
    "      \"numDimensions\": 768,\n",
    "      \"similarity\": \"dotProduct\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad084032",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.query = \"What was the total revenue?\"\n",
    "\n",
    "t.results = t.coll.aggregate([{\n",
    "    \"$vectorSearch\": {\n",
    "        \"queryVector\": t.emb_model.encode(t.query).tolist(),\n",
    "        \"path\": \"embedding\",\n",
    "        \"numCandidates\": 100,\n",
    "        \"limit\": 8,\n",
    "        \"index\": f\"{t.coll.name}_vector_index\"\n",
    "    }}])\n",
    "\n",
    "t.context = \"\\n\\n\".join([d['text'] for d in t.results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd722cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.context[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f530fe39",
   "metadata": {},
   "source": [
    "## Load LLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d990ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# https://python.langchain.com/docs/guides/local_llms\n",
    "t.llm = LlamaCpp(\n",
    "    model_path=t.llm_path,\n",
    "    n_gpu_layers=t.layers,\n",
    "    n_threads=10, \n",
    "    n_ctx=4096, \n",
    "    n_batch=512,\n",
    "    verbose=False,\n",
    "    f16_kv=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    ")\n",
    "\n",
    "# https://llama-cpp-python.readthedocs.io/en/latest/\n",
    "# t.llm = Llama(\n",
    "#     model_path=t.llm_path,\n",
    "#     n_gpu_layers=t.layers,\n",
    "#     n_threads=10, \n",
    "#     n_ctx=4096, \n",
    "#     verbose=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b1f8d",
   "metadata": {},
   "source": [
    "## Query LLaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00875683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(prompt, temp=0.8, top_p=0.95):\n",
    "    out = t.llm.invoke(\n",
    "        prompt, \n",
    "        max_tokens=512, \n",
    "        stop=[\"Q:\"], \n",
    "        temperature=temp,\n",
    "        top_p=top_p,\n",
    "        top_k=10,\n",
    "        repeat_penalty=1.2,\n",
    "#         stream=True,\n",
    "    )\n",
    "#     for c in out:\n",
    "#         print(c[\"choices\"][0][\"text\"], end='')\n",
    "#     print()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ced08d",
   "metadata": {},
   "source": [
    "Prompt Format:\n",
    "```\n",
    "<s>[INST] <<SYS>>\n",
    "{{ system_prompt }}\n",
    "<</SYS>>\n",
    "\n",
    "{{ user_message }} [/INST]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8b4826",
   "metadata": {},
   "source": [
    "### Query with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_context(question, context):\n",
    "    full_prompt = (\n",
    "    \"<s>[INST]<<SYS>>\\n\"\n",
    "    + \"You are a helpful expert financial research assistant.\" \n",
    "    + \"You answer questions about about information contained in a financial report.\"\n",
    "    + \"You will be given the user's question, and the relevant informaton from \" \n",
    "    + \"the financial report. Answer the question using only this information\" \n",
    "    + \"\\n<</SYS>>\\n\\n\"\n",
    "    + \"Information: {context}\\n\"\n",
    "    + \"Question: {question}\\n\"\n",
    "    + \"Answer:\\n\"\n",
    "    + \"[/INST]\"\n",
    "    )\n",
    "    full_prompt = full_prompt.replace(\"{context}\", context)\n",
    "    full_prompt = full_prompt.replace(\"{question}\", question)\n",
    "    ask(full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f655f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_context(question):\n",
    "    results = t.coll.aggregate([{\n",
    "    \"$vectorSearch\": {\n",
    "        \"queryVector\": t.emb_model.encode(question).tolist(),\n",
    "        \"path\": \"embedding\",\n",
    "        \"numCandidates\": 200,\n",
    "        \"limit\": 8,\n",
    "        \"index\": f\"{t.coll.name}_vector_index\"\n",
    "    }}])\n",
    "    result_texts = [d['text'] for d in results]\n",
    "    assert len(result_texts) > 0\n",
    "    context = \"\\n\\n\".join(result_texts)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734656b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_with_rag(question):\n",
    "    context = find_context(question)\n",
    "    ask_with_context(question, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ddcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_rag(\"What was the total revenue?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f676fe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_rag(\"What was the operating income or loss?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6353ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_rag(\"What was the operating income or loss in year 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767730fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_rag(\"Compare the total revenue between the years 2023 and 2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8903370",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_rag(\"What time period does the report cover?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_with_rag(\"Were there any changes to the executive team?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d7bc0",
   "metadata": {},
   "source": [
    "### Query Embedded Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84998c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(question):\n",
    "    prompt = (\n",
    "        f\"<s>[INST]<<SYS>>\\n\"\n",
    "        + f\"You are a helpful expert financial research assistant.\" \n",
    "        + f\"\\n<</SYS>>\\n\\n\"\n",
    "        + f\"Question: {question}\\n\"\n",
    "        + f\"Answer:\\n\"\n",
    "        + f\"[/INST]\"\n",
    "    )\n",
    "    ask(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_llm(\"What was the total revenue of MongoDB in the year ended January 31, 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8691bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_llm(\"Were there any changes to the executive team at MongoDB in the year ended January 31, 2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f596e19f",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca3fdd4",
   "metadata": {},
   "source": [
    "We'll use LangChain to tie this all together into a simple API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c27539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import MongoDBAtlasVectorSearch\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Object()\n",
    "l.llm = t.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab045f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.lang_emb = HuggingFaceEmbeddings(model_name=\"multi-qa-mpnet-base-cos-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ded5b",
   "metadata": {},
   "source": [
    "Check that the embeddings model returns embeddings of the correct size of 768:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l.lang_emb.embed_documents(['This is a test document'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.vector_search = MongoDBAtlasVectorSearch(\n",
    "    t.coll, \n",
    "    l.lang_emb, \n",
    "    index_name=\"mdb_vector_index\",\n",
    "    embedding_key=\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.results = list(l.vector_search.max_marginal_relevance_search(\n",
    "    query=\"What was the total revenue?\",\n",
    "    k = 8,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637bfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deafb7a",
   "metadata": {},
   "source": [
    "### Make a Retriever Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.retriever = l.vector_search.as_retriever(search_kwargs={\"k\": 8})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ece5435",
   "metadata": {},
   "source": [
    "### Make the end-to-end chain object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.qa = RetrievalQA.from_chain_type(\n",
    "    llm=l.llm, \n",
    "    retriever=l.retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae59801",
   "metadata": {},
   "source": [
    "### Query LLM with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3df9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.qa.invoke(\"What was the total revenue?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.qa.invoke(\"What time period does the report cover?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd5839b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.992px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
